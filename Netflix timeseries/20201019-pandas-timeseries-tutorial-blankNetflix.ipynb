{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010229,
     "end_time": "2022-06-14T16:08:49.934142",
     "exception": false,
     "start_time": "2022-06-14T16:08:49.923913",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Getting started with Pandas TimeSeries\n",
    "\n",
    "This notebook is intended to introduce you to the basic Pandas DateTime    \n",
    "The following five points will be covered:\n",
    "\n",
    "1. [Parsing DateTime](#task1)\n",
    "2. [Aggregating columns](#task2)\n",
    "3. [Extracting DateTime properties](#task3)\n",
    "4. [Fitering and Selecting specific durations](#task4)\n",
    "5. [Changing the granularity of the Timeseries](#task5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.007561,
     "end_time": "2022-06-14T16:08:49.949330",
     "exception": false,
     "start_time": "2022-06-14T16:08:49.941769",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Prepare environment and read data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T16:08:49.970721Z",
     "iopub.status.busy": "2022-06-14T16:08:49.969759Z",
     "iopub.status.idle": "2022-06-14T16:08:49.973433Z",
     "shell.execute_reply": "2022-06-14T16:08:49.974043Z",
     "shell.execute_reply.started": "2022-06-14T15:59:37.131490Z"
    },
    "papermill": {
     "duration": 0.017297,
     "end_time": "2022-06-14T16:08:49.974231",
     "exception": false,
     "start_time": "2022-06-14T16:08:49.956934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Constants \n",
    "INPUT_PATH = '/kaggle/input/netflix-shows/netflix_titles.csv'\n",
    "\n",
    "# Libraries \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set default properties for plotting \n",
    "plt.rcParams['figure.figsize'] = [11, 4]\n",
    "plt.rcParams['figure.dpi'] = 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2022-06-14T16:08:49.992390Z",
     "iopub.status.busy": "2022-06-14T16:08:49.991784Z",
     "iopub.status.idle": "2022-06-14T16:08:50.110091Z",
     "shell.execute_reply": "2022-06-14T16:08:50.110668Z",
     "shell.execute_reply.started": "2022-06-14T15:59:37.304590Z"
    },
    "papermill": {
     "duration": 0.129316,
     "end_time": "2022-06-14T16:08:50.110840",
     "exception": false,
     "start_time": "2022-06-14T16:08:49.981524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read data and display 5 random entries \n",
    "raw_df = pd.read_csv(INPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008464,
     "end_time": "2022-06-14T16:08:50.126520",
     "exception": false,
     "start_time": "2022-06-14T16:08:50.118056",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "_____\n",
    "\n",
    "## Task 1: Countthe number of shows added per day     \n",
    "\n",
    "In the following section, we will parse the raw date format into      \n",
    "pandas datetime and summarize the daily shows added to the total number \n",
    "\n",
    "### Parse timestamp into datetime column <a id='task1'></a>\n",
    "\n",
    "Change the raw format to a pandas datetime format.    \n",
    "Once we have changed the format as such, we will be able to    \n",
    "apply more functionalities illustrated below \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T16:08:50.145043Z",
     "iopub.status.busy": "2022-06-14T16:08:50.144282Z",
     "iopub.status.idle": "2022-06-14T16:08:50.376055Z",
     "shell.execute_reply": "2022-06-14T16:08:50.376579Z",
     "shell.execute_reply.started": "2022-06-14T15:59:37.599373Z"
    },
    "papermill": {
     "duration": 0.243174,
     "end_time": "2022-06-14T16:08:50.376765",
     "exception": false,
     "start_time": "2022-06-14T16:08:50.133591",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            number of shows added per day\n",
      "date_added                               \n",
      "2008-01-01                              1\n",
      "2008-02-04                              1\n",
      "2009-05-05                              1\n",
      "2009-11-18                              1\n",
      "2010-11-01                              1\n",
      "...                                   ...\n",
      "2021-09-21                              5\n",
      "2021-09-22                              9\n",
      "2021-09-23                              2\n",
      "2021-09-24                             10\n",
      "2021-09-25                              1\n",
      "\n",
      "[1714 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "df=raw_df.copy()\n",
    "df[\"date_added\"]=pd.to_datetime(df[\"date_added\"])\n",
    "show_Data=df.groupby(\"date_added\")[[\"show_id\"]].count()\n",
    "show_Data=show_Data.rename({\"show_id\":\"number of shows added per day\"} ,axis=1)\n",
    "print (show_Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008744,
     "end_time": "2022-06-14T16:08:50.393227",
     "exception": false,
     "start_time": "2022-06-14T16:08:50.384483",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Count shows added  per date <a id='task2'></a>\n",
    "All the shows have been listed in the original dataframe.     \n",
    "Now let's count the total number of shows added per day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.007312,
     "end_time": "2022-06-14T16:08:50.408632",
     "exception": false,
     "start_time": "2022-06-14T16:08:50.401320",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "______\n",
    "\n",
    "## Task 2: Extract the day name and sum-up the shows added \n",
    "<a id='task3'></a>\n",
    "\n",
    "In the last step, we have used the `date_added` column to count the number of shows.    \n",
    "Since we've used the `groupby` functionality to count the number of shows,     \n",
    "the column is set as our index. \n",
    "\n",
    "We could now use our new index directly to extract the Attributes of the timestamp.    \n",
    "One example of those Attributes is the `day_name`.    \n",
    "Check out the [full list of the attributes here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DatetimeIndex.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T16:08:50.432888Z",
     "iopub.status.busy": "2022-06-14T16:08:50.432158Z",
     "iopub.status.idle": "2022-06-14T16:08:50.447634Z",
     "shell.execute_reply": "2022-06-14T16:08:50.448160Z",
     "shell.execute_reply.started": "2022-06-14T15:59:37.848185Z"
    },
    "papermill": {
     "duration": 0.031553,
     "end_time": "2022-06-14T16:08:50.448356",
     "exception": false,
     "start_time": "2022-06-14T16:08:50.416803",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           number of shows added per day\n",
      "Day_Name                                \n",
      "Friday                              2498\n",
      "Monday                               851\n",
      "Saturday                             816\n",
      "Sunday                               751\n",
      "Thursday                            1396\n",
      "Tuesday                             1197\n",
      "Wednesday                           1288\n"
     ]
    }
   ],
   "source": [
    "show_Data[\"Day_Name\"]=show_Data.index.day_name()\n",
    "total_per_weekday=show_Data.groupby(\"Day_Name\")[[\"number of shows added per day\"]].sum()\n",
    "print(total_per_weekday)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.007644,
     "end_time": "2022-06-14T16:08:50.464689",
     "exception": false,
     "start_time": "2022-06-14T16:08:50.457045",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "______\n",
    "\n",
    "## Task 3: Select data from 2016 onwards \n",
    "<a id='task4'></a>\n",
    "\n",
    "You can also use the regular masking way to select and filter entries.      \n",
    "The syntax is even simpler than one could expect. You don't even need to parse    \n",
    "your filtering criteria to `datetime`. A simple string with `%YYYY-%MM-%DD` format     \n",
    "will do the job  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T16:08:50.487114Z",
     "iopub.status.busy": "2022-06-14T16:08:50.486034Z",
     "iopub.status.idle": "2022-06-14T16:08:50.496702Z",
     "shell.execute_reply": "2022-06-14T16:08:50.497418Z",
     "shell.execute_reply.started": "2022-06-14T16:05:22.732938Z"
    },
    "papermill": {
     "duration": 0.024326,
     "end_time": "2022-06-14T16:08:50.497580",
     "exception": false,
     "start_time": "2022-06-14T16:08:50.473254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            number of shows added per day   Day_Name\n",
      "date_added                                          \n",
      "2016-01-01                             33     Friday\n",
      "2016-01-08                              1     Friday\n",
      "2016-01-13                              1  Wednesday\n",
      "2016-01-15                              2     Friday\n",
      "2016-01-22                              1     Friday\n",
      "...                                   ...        ...\n",
      "2021-09-21                              5    Tuesday\n",
      "2021-09-22                              9  Wednesday\n",
      "2021-09-23                              2   Thursday\n",
      "2021-09-24                             10     Friday\n",
      "2021-09-25                              1   Saturday\n",
      "\n",
      "[1609 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "demo=show_Data.index >= \"01-01-2016\"\n",
    "show_Data=show_Data[demo].copy()\n",
    "print(show_Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008722,
     "end_time": "2022-06-14T16:08:50.515027",
     "exception": false,
     "start_time": "2022-06-14T16:08:50.506305",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "______\n",
    "\n",
    "## Task 4: Sum up weekly data \n",
    "<a id='task5'></a>\n",
    "\n",
    "It is possible to change the granularity of your timeseries directly using Pandas datetie module.        \n",
    "       \n",
    "       \n",
    "To do that, you need to specify two things: \n",
    "- Your new granularity passed as an argument to the `resample` function. [Read more details](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#dateoffset-objects)\n",
    "- The function that will be used to generate the new granularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T16:08:50.536486Z",
     "iopub.status.busy": "2022-06-14T16:08:50.535679Z",
     "iopub.status.idle": "2022-06-14T16:08:50.558382Z",
     "shell.execute_reply": "2022-06-14T16:08:50.559148Z",
     "shell.execute_reply.started": "2022-06-14T16:08:22.420712Z"
    },
    "papermill": {
     "duration": 0.036302,
     "end_time": "2022-06-14T16:08:50.559393",
     "exception": false,
     "start_time": "2022-06-14T16:08:50.523091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            number of shows added per day\n",
      "date_added                               \n",
      "2016-01-03                             33\n",
      "2016-01-10                              1\n",
      "2016-01-17                              3\n",
      "2016-01-24                              2\n",
      "2016-01-31                              4\n",
      "...                                   ...\n",
      "2021-08-29                             55\n",
      "2021-09-05                             81\n",
      "2021-09-12                             28\n",
      "2021-09-19                             49\n",
      "2021-09-26                             28\n",
      "\n",
      "[300 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Use the resampling function to group data per week\n",
    "weekly_data = (show_Data.\n",
    "               resample('1W')   # For each week \n",
    "               .sum())          # Calculate the sum\n",
    "print(weekly_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 5.729813,
   "end_time": "2022-06-14T16:08:50.675616",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-06-14T16:08:44.945803",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
